# ai_summarizer.py
import logging
import sys
from typing import Optional
from config import GitReportConfig
import os

# (V3.4) å¯¼å…¥æŠ½è±¡å±‚å’Œå…·ä½“ç­–ç•¥
from llm.provider_abc import LLMProvider
from llm.gemini_provider import GeminiProvider
from llm.deepseek_provider import DeepSeekProvider

# (V3.4) ä¿ç•™å¯¼å…¥
try:
    from google import genai
    from google.genai.errors import APIError
except ImportError:
    pass

logger = logging.getLogger(__name__)


# --- (V3.4) å·¥å‚å‡½æ•° (V3.5 ä¿æŒä¸å˜) ---
def get_llm_provider(provider_id: str, config: GitReportConfig) -> LLMProvider:
    """
    (V3.4) å·¥å‚å‡½æ•°ï¼Œæ ¹æ® provider_id é€‰æ‹©å¹¶å®ä¾‹åŒ–æ­£ç¡®çš„ LLM ä¾›åº”å•†ã€‚
    """
    logger.info(f"â„¹ï¸ (V3.4) æ­£åœ¨å°è¯•åˆå§‹åŒ– LLM ä¾›åº”å•†: {provider_id}")

    if not config.is_provider_configured(provider_id):
        logger.error(f"âŒ (V3.4) ä¾›åº”å•† '{provider_id}' æœªé…ç½®ã€‚")
        raise ValueError(
            f"ä¾›åº”å•† '{provider_id}' æœªé…ç½®ã€‚ "
            f"è¯·åœ¨æ‚¨çš„ .env æ–‡ä»¶ä¸­è®¾ç½®ç›¸åº”çš„ API å¯†é’¥ã€‚"
        )
    try:
        if provider_id == "gemini":
            return GeminiProvider(config)
        elif provider_id == "deepseek":
            return DeepSeekProvider(config)

        logger.error(f"âŒ (V3.4) æœªçŸ¥çš„ LLM ä¾›åº”å•†: {provider_id}")
        raise ValueError(f"æœªçŸ¥çš„ LLM ä¾›åº”å•†: {provider_id}")
    except ImportError as e:
        logger.error(f"âŒ (V3.4) å¯¼å…¥ä¾›åº”å•† '{provider_id}' å¤±è´¥ã€‚")
        logger.error(
            f"   è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ– (ä¾‹å¦‚ 'pip install google-generativeai openai')ã€‚"
        )
        raise ImportError(f"ä¾›åº”å•† '{provider_id}' ä¾èµ–ç¼ºå¤±: {e}")
    except Exception as e:
        logger.error(f"âŒ (V3.4) å®ä¾‹åŒ–ä¾›åº”å•† '{provider_id}' å¤±è´¥: {e}")
        raise


# --- (V3.5) AIService (ä¸Šä¸‹æ–‡) ---
class AIService:
    """
    (V3.5 é‡æ„) å°è£…æ‰€æœ‰å¯¹ LLM çš„è°ƒç”¨ã€‚
    - æç¤ºè¯åŠ è½½é€»è¾‘å·²ç§»è‡³ Providerã€‚
    - AIService åªè´Ÿè´£ä¼ é€’*åŸå§‹æ•°æ®*ã€‚
    """

    def __init__(self, config: GitReportConfig, provider_id: str):
        """
        (V3.4) åˆå§‹åŒ– AI æœåŠ¡
        """
        self.config = config
        self.provider: LLMProvider = get_llm_provider(provider_id, config)
        logger.info(
            f"âœ… ğŸ¤– AI æœåŠ¡å·²æˆåŠŸåˆå§‹åŒ– (Provider: {self.provider.__class__.__name__})"
        )

    # --- (V3.5) Prompt åŠ è½½å™¨ (å·²ç§»é™¤) ---
    # _load_prompt_template å’Œ _generate_content å·²è¢«ç§»é™¤ã€‚

    # --- (V3.5) é‡æ„æ‰€æœ‰ AI è°ƒç”¨æ–¹æ³• (çº¯å§”æ‰˜) ---

    def get_single_diff_summary(self, diff_content: str) -> Optional[str]:
        """
        (V3.5 é‡æ„) å§”æ‰˜ Provider æ€»ç»“ diffã€‚
        """
        if len(diff_content) > 100000:
            logger.warning(
                f"âš ï¸ Diff å†…å®¹è¿‡é•¿ ({len(diff_content)} chars)ï¼Œè·³è¿‡ AI æ€»ç»“ã€‚"
            )
            return "(Diff å†…å®¹è¿‡é•¿ï¼Œå·²è·³è¿‡æ€»ç»“)"

        try:
            # (V3.5) çº¯å§”æ‰˜
            summary = self.provider.summarize_diff(diff_content)
            if summary:
                # (V3.3) çš„ç‰¹å®šåå¤„ç†ä»ç„¶ä¿ç•™
                return summary.strip().replace("\n", " ")
            return None
        except Exception as e:
            logger.error(f"âŒ (V3.5) get_single_diff_summary å¤±è´¥: {e}")
            return None

    def get_ai_summary(
        self,
        text_report: str,
        diff_summaries: Optional[str] = None,
        previous_summary: Optional[str] = None,
    ) -> Optional[str]:
        """
        (V3.5 é‡æ„) å§”æ‰˜ Provider ç”Ÿæˆæœ€ç»ˆæ‘˜è¦ã€‚
        """
        try:
            # (V3.5) çº¯å§”æ‰˜
            return self.provider.summarize_report(
                text_report, diff_summaries, previous_summary
            )
        except Exception as e:
            logger.error(f"âŒ (V3.5) get_ai_summary å¤±è´¥: {e}")
            return None

    def distill_project_memory(self) -> Optional[str]:
        """
        (V3.5 é‡æ„) å§”æ‰˜ Provider è’¸é¦è®°å¿†ã€‚
        """
        logger.info("ğŸ§  æ­£åœ¨å¯åŠ¨ AI 'è®°å¿†è’¸é¦' é˜¶æ®µ...")

        log_file_path = os.path.join(
            self.config.PROJECT_DATA_PATH, self.config.PROJECT_LOG_FILE
        )
        try:
            with open(log_file_path, "r", encoding="utf-8") as f:
                full_log = f.read()
        except FileNotFoundError:
            logger.info(f"â„¹ï¸ æœªæ‰¾åˆ°é¡¹ç›®æ—¥å¿— ({log_file_path})ï¼Œå°†åˆ›å»ºæ–°è®°å¿†ã€‚")
            return None
        except Exception as e:
            logger.error(f"âŒ è¯»å–é¡¹ç›®æ—¥å¿—å¤±è´¥ ({log_file_path}): {e}")
            return None

        if not full_log.strip():
            logger.info("â„¹ï¸ é¡¹ç›®æ—¥å¿—ä¸ºç©ºï¼Œæ— éœ€è’¸é¦ã€‚")
            return None

        try:
            # (V3.5) çº¯å§”æ‰˜
            return self.provider.distill_memory(full_log)
        except Exception as e:
            logger.error(f"âŒ (V3.5) distill_project_memory å¤±è´¥: {e}")
            return None

    def generate_public_article(
        self,
        today_technical_summary: str,
        project_historical_memory: str,
        project_readme: Optional[str] = None,
    ) -> Optional[str]:
        """
        (V3.5 é‡æ„) å§”æ‰˜ Provider ç”Ÿæˆå…¬ä¼—å·æ–‡ç« ã€‚
        """
        logger.info("âœï¸ æ­£åœ¨å¯åŠ¨ AI 'é£æ ¼è½¬æ¢' é˜¶æ®µ (ç”Ÿæˆå…¬ä¼—å·æ–‡ç« )...")
        try:
            # (V3.5) çº¯å§”æ‰˜
            return self.provider.generate_article(
                today_technical_summary, project_historical_memory, project_readme
            )
        except Exception as e:
            logger.error(f"âŒ (V3.5) generate_public_article å¤±è´¥: {e}")
            return None
